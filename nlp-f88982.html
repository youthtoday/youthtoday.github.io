<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<!-- iOS Safari -->
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<!-- Chrome, Firefox OS and Opera Status Bar Color -->
<meta name="theme-color" content="#FFFFFF">
<link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
<link rel="stylesheet" type="text/css"
  href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
<link rel="stylesheet" type="text/css" href="css/SourceSansPro.css">
<link rel="stylesheet" type="text/css" href="css/theme.css">
<link rel="stylesheet" type="text/css" href="css/notablog.css">
<!-- Favicon -->

  <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;📖&lt;/text&gt;&lt;/svg&gt;">

<style>
  :root {
    font-size: 20px;
  }
</style>
  <title>NLP复习&nbsp;|&nbsp;Nick的博客</title>
  <meta property="og:type" content="blog">
  <meta property="og:title" content="NLP复习">
  
  
  <style>
    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
</head>

<body>
  <nav class="Navbar">
  <a href="index.html">
    <div class="Navbar__Btn">
      
        <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;📖&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
      
      <span>Home</span>
    </div>
  </a>
  
    
  
    
  
    
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="-fe1f32.html">
        <div class="Navbar__Btn">
          
            <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;📚&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
          
          <span>分类</span>
        </div>
      </a>
    
  
    
      <span class="Navbar__Delim">&centerdot;</span>
      <a href="about.html">
        <div class="Navbar__Btn">
          
            <span><img class="inline-img-icon" src="data:image/svg+xml,&lt;svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22&gt;&lt;text text-anchor=%22middle%22 dominant-baseline=%22middle%22 x=%2250%22 y=%2255%22 font-size=%2280%22&gt;😀&lt;/text&gt;&lt;/svg&gt;"></span>&nbsp;
          
          <span>关于我</span>
        </div>
      </a>
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
</nav>
  <header class="Header">
    
    <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
    
    <h1 class="Header__Title">NLP复习</h1>
    
  </header>
  <article id="https://www.notion.so/f889828019c7447d823bb7bd28bd79be" class="PageRoot"><h1 id="https://www.notion.so/9a10c2c5ee274d539581634572954649" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/9a10c2c5ee274d539581634572954649"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Topic Overview</span></span></h1><div id="https://www.notion.so/7cc5b014882347f49941a75e75f6479e" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">(*) indicates that you should be familiar with the basic concept, but details will not be tested on the exam.</span></span></p></div><div id="https://www.notion.so/3c24a114455643efbcad5d16b376c509" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">General Linguistics Concepts </strong></span><span class="SemanticString">(Parts of J&amp;M 2nd ed. Ch 1 but mostly split over different chapters in J&amp;M. Ch.1 not yet available in 3rd ed.)</span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/3f30c3f3347d46d78b704e40d75cc884" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Levels of linguistic representation: phonetics/phonology, morphology, syntax, semantics, pragmatics</span></span></li><li id="https://www.notion.so/2dafa6e604294cd8b7b86359ad3fd832" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Ambiguity, know some examples in syntax and semantics, including PP attachment, noun-noun compounds.</span></span></li><li id="https://www.notion.so/fa376bfd9666452b80066db15d6f026e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Garden-path sentences.</span></span></li><li id="https://www.notion.so/7ce734bf10844faaac1dfa3b1876e111" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Type/Token distinction.</span></span></li><li id="https://www.notion.so/790aa64494e34b83bf3c18e3f5d1d07c" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Know the following terms: word form, stem, lemma.</span></span></li><li id="https://www.notion.so/6d51548e994549dbb4123c2b3c75a880" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Parts of speech:</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/b1fb7032cdd54185a6e345f501364991" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">know the 9 traditional POS and some of the Penn Treebank tags (but no need to remember the complete tagset).</span></span></li></ul></li><li id="https://www.notion.so/071ed54848c344f99075ab14700c2607" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Types of Linguistic Theories (Prescriptive, Descriptive, Explanatory)</span></span></li><li id="https://www.notion.so/6b45482a6e0c412d837694681f2076ae" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Syntax:</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/433f33f9c6a14b039876947a502bf326" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Constituency and Recursion. Constituency tests (*).</span></span></li><li id="https://www.notion.so/8f1f065b437f44d19df73aa2aca692ee" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Dependency.</span></span></li><li id="https://www.notion.so/d94729de8d634f439b18f4151f7960ba" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Grammatical Relations.</span></span></li><li id="https://www.notion.so/3c5b8831bf6740d196ae01e98390f3df" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Subcategorization</span></span></li><li id="https://www.notion.so/61b5b4df40874829a8394156a35b396b" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Long-distance dependencies. (*)</span></span></li><li id="https://www.notion.so/6a316270eca6434e8e680ebf87c9ba63" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Syntactic heads (connection between dependency and constituency structure).</span></span></li><li id="https://www.notion.so/fe2fd5dfaab14a36b7ee681eb29c7d4a" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Center embeddings.</span></span></li><li id="https://www.notion.so/2953045ad6b1472db9edcd015c54d435" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Dependency syntax:</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/0ecb03409fbb4695b6f85d25df75e240" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Head, dependent</span></span></li><li id="https://www.notion.so/cf7f26321d6b4482a192814fbe2ba85f" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Dependency relations and labels</span></span></li><li id="https://www.notion.so/f120b473010944a8897fb5728ed81168" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Projectivity</span></span></li></ul></li></ul></li></ul><div id="https://www.notion.so/53b9afa5af6240df8d1b3b54a8d37e54" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Text Processing </strong></span><span class="SemanticString">(Split over different chapters in J&amp;M. Parts of </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://web.stanford.edu/~jurafsky/slp3/6.pdf">J&amp;M 3rd ed. Ch. 6)</a></span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/25b81edb187b4024b5859119f9165d2a" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Tokenization (word segmentation).</span></span></li><li id="https://www.notion.so/901803bb1add48c18dde41de1eb38cb4" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Sentence splitting.</span></span></li><li id="https://www.notion.so/a0b1621734a7450ba17b86e602f2afba" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Lemmatization.</span></span></li></ul><div id="https://www.notion.so/98ee058b2810432ab992138903ff6240" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Probability Background</strong></span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/0c8039961dee4de7a9b67535246a9047" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Prior vs. conditional probability.</span></span></li><li id="https://www.notion.so/527802e7f209435c99a75e363b513fbc" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Sample space, basic outcomes</span></span></li><li id="https://www.notion.so/b585cd02661942eba27fbd581cd3fa24" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Probability distribution</span></span></li><li id="https://www.notion.so/818e4a418ea549dda7859eecc82b1727" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Events</span></span></li><li id="https://www.notion.so/dba767bd48f34df4966a2a718682855c" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Random variables</span></span></li><li id="https://www.notion.so/7b08e22bd04e4c348b07d060ab3f9ead" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Bayes&#x27; rule</span></span></li><li id="https://www.notion.so/a3efd3a360ac4536bde04a5e6f353ce1" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">conditional independence</span></span></li><li id="https://www.notion.so/108c79b499c6491586389a73b25d4877" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">discriminative vs. generative models</span></span></li><li id="https://www.notion.so/73571d5ee8904d4891761f0711ea75b1" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Noisy channel model.</span></span></li><li id="https://www.notion.so/1fb835da2da2482292bd5e6172bc668c" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Calculating with probabilities in log space.</span></span></li></ul><div id="https://www.notion.so/8b200d128c52439e82e62e02d443baae" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Text Classification (</strong></span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://web.stanford.edu/~jurafsky/slp3/6.pdf">J&amp;M 3rd ed. Ch. 6</a></span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">)</strong></span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/988e583938c344c5afa1790f98685ee0" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Task definition and applications</span></span></li><li id="https://www.notion.so/8f6d4aa4a1374bfb856e864a3e48e70f" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Document representation: Set/Bag-of-words, vector space model</span></span></li><li id="https://www.notion.so/37eff4b947664cc59555084f0b18adf5" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Naive Bayes&#x27; and independence assumptions in text classification.</span></span></li></ul><div id="https://www.notion.so/d63bbff667034a698c513ca818c21970" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Language Models (</strong></span><span class="SemanticString">J&amp;M 2nd ed. Ch 4.1-4.8, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://web.stanford.edu/~jurafsky/slp3/4.pdf">J&amp;M 3rd ed. Ch 4</a></span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">)</strong></span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/d1f379627d2841e9a5e85539d6c1fc7e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Task definition and applications</span></span></li><li id="https://www.notion.so/a9b5d22d8e904472b1d540bf8774614b" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Probability of the next word and probability of a sentence</span></span></li><li id="https://www.notion.so/ee7251a342e64127b22808e01fa9584c" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Markov independence assumption.</span></span></li><li id="https://www.notion.so/2f69a88505bd41e8b9e1c438547bd736" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">n-gram language models.</span></span></li><li id="https://www.notion.so/5124a49395d54eefa64f0c847ffec05e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Role of the START and END markers.</span></span></li><li id="https://www.notion.so/06961a074ab845fd9b331f5c90656f51" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Estimating ngram probabilities from a corpus:</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/77a46f39347b44a8bf69e483a1e105c2" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Maximum Likelihood Estimates</span></span></li><li id="https://www.notion.so/b43d519f9ab348e68464db759a8ba1a3" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Dealing with unseen Tokens</span></span></li><li id="https://www.notion.so/f0c7a9e1b5f04d7aaacec3374abb86c1" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Smoothing and Back-off:</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/da56f973619a45e58eba37c711f49f85" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Additive Smoothing</span></span></li><li id="https://www.notion.so/cc43c8c2cd744344864eeb885ca2bc8e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Discounting</span></span></li><li id="https://www.notion.so/106d9e00aff2453692482f3e1044d287" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Linear Interpolation</span></span></li><li id="https://www.notion.so/3bfb0db99b364058b3ed1cc147f30289" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Katz&#x27; Backoff</span></span></li></ul></li></ul></li><li id="https://www.notion.so/bddf97dda2f940e6805f76f14bd8968c" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Perplexity</span></span></li></ul><div id="https://www.notion.so/83c03993bc47419ba700eb8696558a81" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Sequence Labeling (POS tagging) (</strong></span><span class="SemanticString">J&amp;M 2nd ed Ch 5.1-5.5, </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://web.stanford.edu/~jurafsky/slp3/10.pdf">J&amp;M 3rd ed. Ch 10.1-10.4</a></span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">)</strong></span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/dd50bca151ef4eabbcacd2fae4d4920c" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Linguistic tests for part of speech (*).</span></span></li><li id="https://www.notion.so/987b39b9224d4d45bdd319a0a5a873c0" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Hidden Markov Model:</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/ce8751755a6046099b258c8efa36a449" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Observations (sequence of tokens)</span></span></li><li id="https://www.notion.so/9b7a61cc6a634357a1dde045b1abdef2" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Hidden states (sequence of part of speech tags)</span></span></li><li id="https://www.notion.so/0af0f383050e44a6b02b8e53a04e4e6a" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Transition probabilities, emission probabilities</span></span></li><li id="https://www.notion.so/b6d85742e6b24c31bfc9dc8ebdca82bd" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Markov chain</span></span></li><li id="https://www.notion.so/951d8f28ea3142479bc77f2e86d7979a" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Three tasks on HMMs: Decoding, Evaluation, Training</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/f1d0f472e61c427ca384d893d449b8ae" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Decoding: Find the most likely sequence of tags:</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/c55e95cb17b6456099af7f2b1097fcc3" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Viterbi algorithm (dynamic programming, know the algorithm and data structures involved)</span></span></li></ul></li><li id="https://www.notion.so/c49eb0ca098c499797241e8dbc79f268" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Evaluation: Find the probability of a sequence of words</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/fee527ecd0254f7b9c25775f25512cd1" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Spurious ambiguity: multiple hidden sequences lead to the same observation.</span></span></li><li id="https://www.notion.so/7bcbdd1612664c8aa23a21d2c0540c68" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Forward algorithm (difference to Viterbi).</span></span></li></ul></li><li id="https://www.notion.so/f1f16fc493c24cbf901c0510632cee98" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Training: We only discussed maximum likelihood estimates.</span></span></li></ul></li><li id="https://www.notion.so/348f26da062e4d3ca5d86ce9f516c29a" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Extending HMMs to trigrams. (*)</span></span></li></ul></li><li id="https://www.notion.so/10354e2010b94afc983d50932340a4f3" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Applying HMMs to other sequence labeling tasks, for example Named Entity Recognition</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/bb83d4d132d04f75b1aed2885de6be45" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">B.I.O. tags for NER.</span></span></li></ul></li></ul><div id="https://www.notion.so/03f17c989fdd4e658c7d91c144a78506" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Parsing with Context Free Grammars (</strong></span><span class="SemanticString">J&amp;M 2nd ed Ch. 12 and 13.1-13.4</span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold"> </strong></span><span class="SemanticString">and 14.1-14.4 and Ch. 16, </span><span class="SemanticString">                                                                  </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://web.stanford.edu/~jurafsky/slp3/11.pdf">J&amp;M 3rd ed. Ch. 11.1-11.5</a></span><span class="SemanticString">and </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://web.stanford.edu/~jurafsky/slp3/13.pdf">Ch 13.1-13.4</a></span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/539fa4bc4000487da4e873fc4371dd7e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Tree representation of constituency structure. Phrase labels.</span></span></li><li id="https://www.notion.so/97e8073e23d64330b342ea7e2cf105a6" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">CFG definition: terminals, nonterminals, start symbol, productions/rules</span></span></li><li id="https://www.notion.so/d74620f391a64ce69ce31fa29e124d65" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">derivations and language of a CFG.</span></span></li><li id="https://www.notion.so/38ba459f11b64fd6843fac46af16a1cc" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">derivation trees (vs. derived string), parse tree.</span></span></li><li id="https://www.notion.so/80682f087c404c95b74e38c0d2850577" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Regular grammars / languages(*)</span></span></li><li id="https://www.notion.so/fd42a6b8ef3d40b5a868ffb649741ff3" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Complexity classes.</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/5e33fe42701c4c5d8c9b86f46d894fbd" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">&quot;Chomsky hierarchy&quot;</span></span></li><li id="https://www.notion.so/d2344870c3c74d2b8494873ae379c715" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Center embeddings as an example of a non-regular phenomenon.</span></span></li><li id="https://www.notion.so/2fb54dc8798b40758dd4ed920328f39a" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Cross-serial dependencies as an example of a non-context-free phenomenon. (*)</span></span></li></ul></li><li id="https://www.notion.so/6f24208dc98c4b5494e1e596f5dfddd0" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Probabilitistic context free grammars (PCFG):</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/0445bfd53b084274a28b4d4b3b64827f" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Probability of a tree vs. probability of a sentence.</span></span></li><li id="https://www.notion.so/360789feb3ed4a6c9931075ea26b8bdf" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Maximum likelihood estimates from treebanks.</span></span></li><li id="https://www.notion.so/3ec16706690f43b6ad63c5c34084e5c3" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Computing the most likely parse tree using CKY.</span></span></li></ul></li><li id="https://www.notion.so/1e068b941b0a48d7bf5a3ee964335b36" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Recognition (membership checking) problem vs. parsing</span></span></li><li id="https://www.notion.so/eb5a31bc1b874be5b1f827f3107c355f" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Top-down vs.</span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold"> bottom-up parsing.</strong></span></span></li><li id="https://www.notion.so/829220a17b4046608e70c36b031005a7" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">CKY parser:</strong></span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/1351155a351d45d6a5b8023a656f0875" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">bottom-up approach.</span></span></li><li id="https://www.notion.so/498d36a9db504bfdab742038ac68e8d1" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Chomsky normal form.</span></span></li><li id="https://www.notion.so/f169d76f53a148cd8bc1d9e278803a7c" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Dynamic programming algorithm. (know the algorithm and required data structure: CKY parse table). Split position.</span></span></li><li id="https://www.notion.so/5a465cc3940f45358875599e9fa55c1c" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Backpointers.</span></span></li><li id="https://www.notion.so/563345ea14ed49408f1f08e26ebeeef4" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Parsing with PCFGs</span></span></li></ul></li></ul><div id="https://www.notion.so/915ef14b98894390abe7c237d5e3ecb3" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Dependency parsing (</strong></span><span class="SemanticString"> </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://web.stanford.edu/~jurafsky/slp3/14.pdf">J&amp;M 3rd ed. Ch 14.1-14.5</a></span><span class="SemanticString">                                     Supplementary material: </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://courseworks2.columbia.edu/courses/103731/files/7951591/download?wrap=1">Küber, McDonald, and Nivre (2009): Dependency Parsing, Ch.1 to 4.2</a></span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://courseworks2.columbia.edu/courses/103731/files/7951591/download?download_frd=1"> </a></span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://courseworks2.columbia.edu/courses/103731/files/7951591/download?download_frd=1"> </a></span><span class="SemanticString">)</span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/85bed3367cd14ce48f7455151d4bcf83" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Transition based dependency parsing:</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/d98c18e9efea4b7b808e65d390cc009a" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">States (configuration): Stack, Buffer, Partial dependency tree A</span></span></li><li id="https://www.notion.so/d7ad6f4bfbf54edd85590bc8c892a76e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Transitions (Arc-standard system): Shift, Left-Arc, Right-Arc</span></span></li><li id="https://www.notion.so/8514393592b74a958f1c05992f02cfd8" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Predicting the next transition using discriminative classifiers.</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/5f5f0cfc834945d681823f7e512f6e33" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Feature definition (address + attribute)</span></span></li></ul></li><li id="https://www.notion.so/6e0da91109b44b3bb57fac30c1c80a7b" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Training the parser from a treebank:</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/10da15c3d2194406adbb27cf4d38c863" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Oracle transitions from annotated dependency tree.</span></span></li></ul></li><li id="https://www.notion.so/6ef7aeb5e0ba413791346edc6de79f4a" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Arc-eager system (*)</span></span></li></ul></li><li id="https://www.notion.so/7dd673a58410499ba1e9eeb17a502eb4" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Graph-based dependency parsing (* know the general idea: each word needs to get a head, start with completely connected graph, score each edge, keep the highest scoring edges)</span></span></li></ul><div id="https://www.notion.so/dd46985b17484e518940b6dad0eacfc4" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">Machine Learning </strong></span><span class="SemanticString">(Some textbook references below)</span></span></p></div><ul class="BulletedListWrapper"><li id="https://www.notion.so/994fc0fb8df5495987d7e86c19339b36" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Generative vs. discriminative algorithms</span></span></li><li id="https://www.notion.so/7f2716046fa64cea9d451b0ad6fd6933" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Supervised learning. Classification vs. regression problems, multi-class classification</span></span></li><li id="https://www.notion.so/bb66349d0f9a4ca7b0071a1d3747aa1c" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Loss functions: Least squares error (*). Classification error.</span></span></li><li id="https://www.notion.so/6ff4cff5b83a4468be50162e8370f1f9" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Training (empirical risk) vs. testing error (validation risk). Overfitting.</span></span></li><li id="https://www.notion.so/073f12ea292942fdaa05990a2220c660" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Linear Models.</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/ebf129b3d38a4f3fa88346d8501a8652" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">activation function. (step function)</span></span></li><li id="https://www.notion.so/4c32770b59a641378692b451c37a6a69" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Bias weight</span></span></li><li id="https://www.notion.so/1bdebdfa25664bf6abf08820b05f9214" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">perceptron learning algorithm (*)</span></span></li><li id="https://www.notion.so/2f931d6f1a234bd098feea6a740fecbc" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">linear separability and the XOR problem. (*)</span></span></li></ul></li><li id="https://www.notion.so/3392c7eab0e24f6fb74087edc5e03478" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Feature functions</span></span></li><li id="https://www.notion.so/0968f870695944a4929067abe022a459" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Log-linear models</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/b7595d1bd4d641d78414225c25d05775" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">model formulation</span></span></li><li id="https://www.notion.so/6d162d09a7d44d5c866cde4050dae73e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">logistic regression and logits (*)</span></span></li><li id="https://www.notion.so/113d33ac27734e5b95b452f5e507e6a3" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">log likelihood as a function of the weight vector.</span></span></li><li id="https://www.notion.so/8fd70643d1ed4d3cbe8b4960bf31e4ab" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">gradient ascent</span></span></li><li id="https://www.notion.so/b930e8ebc421438fbfbbc2d5b9716893" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">derivative of the log likelihood function (*)</span></span></li><li id="https://www.notion.so/a6da308b2dc947858b6cb8471982a42e" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">regularization (*)</span></span></li><li id="https://www.notion.so/0b5e24097b054b50910b1ee69798b4dd" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Maximum Entropy Markov Models (for POS tagging)</span></span></li></ul></li><li id="https://www.notion.so/09adf7b915b547ec8892e6c763d02f65" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Feed-forward neural nets (J&amp;M 3rd. ed. ch. 8, as well as Goldberg Ch 3. &amp; 5.1)</span></span><ul class="BulletedListWrapper"><li id="https://www.notion.so/28fe94f6c7364445a2be59c7055bc8c4" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Multilayer neural nets.</span></span></li><li id="https://www.notion.so/8790405918b64b5dbf5e1df7aebc6bd4" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Different activation functions (sigmoid, ReLU, tanh)</span></span></li><li id="https://www.notion.so/046ea84844e24ee0a92b071424133679" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Computation Graph.</span></span></li><li id="https://www.notion.so/d21d99e5dfd94d91b6c2a5ae21bb7a02" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Softmax.</span></span></li><li id="https://www.notion.so/d047df231b0e4a8fa4ca503568891784" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Backpropagation (*) (know the idea of propagating back partial derivatives of the loss with respect to each weight -- you won&#x27;t have to do calculus on the final).</span></span></li><li id="https://www.notion.so/b2804863cbbf46f69c09e3016de2dddc" class="BulletedList"><span class="SemanticStringArray"><span class="SemanticString">Neural language model (Goldberg Ch. 9.4, J&amp;M SLP 3rd. edition Ch. 6.2-6.5 )</span></span></li></ul><div id="https://www.notion.so/bca509677b1b430db7c9feee713c9d86" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div></li></ul><h1 id="https://www.notion.so/679f41d162ed4aae9814a66438bdcbfc" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/679f41d162ed4aae9814a66438bdcbfc"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">Naive Bayes</span></span></h1><div id="https://www.notion.so/1cd74dc98c6b435983f61d524ddb59bb" class="Image Image--PageWidth"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd84082e4-be9d-4023-8f1f-2ac4cdec1e11%2FUntitled.png?width=1414&amp;table=block&amp;id=1cd74dc9-8c6b-4359-83f6-1d524ddb59bb"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fd84082e4-be9d-4023-8f1f-2ac4cdec1e11%2FUntitled.png?width=1414&amp;table=block&amp;id=1cd74dc9-8c6b-4359-83f6-1d524ddb59bb" style="width:100%"/></a><figcaption><span class="SemanticStringArray"></span></figcaption></figure></div><div id="https://www.notion.so/2853f566c6524b709e6841dd96b23aec" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div></article>
    <script src="https://utteranc.es/client.js"
        repo="youthtoday/youthtoday.github.io"
        issue-term="pathname"
        label="✨"
        theme="github-light"
        crossorigin="anonymous"
        async>
    </script>
  <footer class="Footer">
  <div>&copy; Nick的博客 2022</div>
  <div>&centerdot;</div>
  <div>Powered by <a href="https://github.com/dragonman225/notablog" target="_blank"
      rel="noopener noreferrer">Notablog</a>.
  </div>
</footer>
</body>

</html>
